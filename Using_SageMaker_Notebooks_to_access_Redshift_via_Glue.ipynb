{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Amazon SageMaker to Access AWS Redshift Tables Defined in AWS Glue Data Catalog\n",
    "====================\n",
    "\n",
    "This notebook demonstrates accessing Redshift datasets defined in the Glue Data Catalog data from a SageMaker notebook. \n",
    "\n",
    "Access occurs via:\n",
    "* a Sparkmagic (https://github.com/jupyter-incubator/sparkmagic) notebook (PySpark) \n",
    "* Apache Livy (https://livy.incubator.apache.org/), running on an EMR cluster\n",
    "* The EMR cluster has the Redshift driver installed, and uses the Glue Data Catalog as its metastore\n",
    "* Uses the EMR metastore to check datasets defined in a Glue Data Catalog\n",
    "* Uses connection information retrieved from the Glue Data Catalog to access a Redshift cluster, from EMR\n",
    "* Reads datasets from Redshift into EMR\n",
    "* Returns the data from EMR as a dataframe for local access in the SageMaker Notebook.\n",
    "\n",
    "In order to set this up, follow the instructions in the accompanying blog post, here [[TO DO - INSERT LINK TO BLOG POST ]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Set up access to the Glue Data Catalog](#emr_setup)\n",
    "1. [Access Glue Data Catalog using SQL magics](#glue_access)   \n",
    "1. [Access Redshift data](#redshift_access)\n",
    "1. [Using the Data on the Local Notebook](#local_access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Access to the Amazon Glue Data Catalog<a name='emr_setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook is written to run on a SageMaker notebook instance. It uses SparkMagic (PySpark) to access Apache Spark, running on Amazon EMR. \n",
    "\n",
    "The EMR cluster runs Spark and Apache Livy, and must be set up to use the AWS Glue Data Store for its Hive metastore.\n",
    "\n",
    "In addition, the SageMaker notebook instance must be configured to access Livy.\n",
    "\n",
    "This configuration is established in the accompanying blog post [[UPDATE WITH NAME AND LINK]].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now:\n",
    "* Check that this notebook is using SparkMagic (PySpark) (look in the top right corner).\n",
    "* Restarted the kernel of this notebook (Kernel -> Restart -> Restart).\n",
    "* If you've left the notebook for some time, also restart the kernel and re-execute the cells. This is because the Livy connection times out.\n",
    "\n",
    "Then, print out the list of Livy magic commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <th>Magic</th>\n",
       "    <th>Example</th>\n",
       "    <th>Explanation</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>info</td>\n",
       "    <td>%%info</td>\n",
       "    <td>Outputs session information for the current Livy endpoint.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>cleanup</td>\n",
       "    <td>%%cleanup -f</td>\n",
       "    <td>Deletes all sessions for the current Livy endpoint, including this notebook's session. The force flag is mandatory.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>delete</td>\n",
       "    <td>%%delete -f -s 0</td>\n",
       "    <td>Deletes a session by number for the current Livy endpoint. Cannot delete this kernel's session.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>logs</td>\n",
       "    <td>%%logs</td>\n",
       "    <td>Outputs the current session's Livy logs.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>configure</td>\n",
       "    <td>%%configure -f<br/>{\"executorMemory\": \"1000M\", \"executorCores\": 4}</td>\n",
       "    <td>Configure the session creation parameters. The force flag is mandatory if a session has already been\n",
       "    created and the session will be dropped and recreated.<br/>Look at <a href=\"https://github.com/cloudera/livy#request-body\">\n",
       "    Livy's POST /sessions Request Body</a> for a list of valid parameters. Parameters must be passed in as a JSON string.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>spark</td>\n",
       "    <td>%%spark -o df<br/>df = spark.read.parquet('...</td>\n",
       "    <td>Executes spark commands.\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-o VAR_NAME: The Spark dataframe of name VAR_NAME will be available in the %%local Python context as a\n",
       "          <a href=\"http://pandas.pydata.org/\">Pandas</a> dataframe with the same name.</li>\n",
       "        <li>-m METHOD: Sample method, either <tt>take</tt> or <tt>sample</tt>.</li>\n",
       "        <li>-n MAXROWS: The maximum number of rows of a dataframe that will be pulled from Livy to Jupyter.\n",
       "            If this number is negative, then the number of rows will be unlimited.</li>\n",
       "        <li>-r FRACTION: Fraction used for sampling.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>sql</td>\n",
       "    <td>%%sql -o tables -q<br/>SHOW TABLES</td>\n",
       "    <td>Executes a SQL query against the variable sqlContext (Spark v1.x) or spark (Spark v2.x).\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-o VAR_NAME: The result of the SQL query will be available in the %%local Python context as a\n",
       "          <a href=\"http://pandas.pydata.org/\">Pandas</a> dataframe.</li>\n",
       "        <li>-q: The magic will return None instead of the dataframe (no visualization).</li>\n",
       "        <li>-m, -n, -r are the same as the %%spark parameters above.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>local</td>\n",
       "    <td>%%local<br/>a = 1</td>\n",
       "    <td>All the code in subsequent lines will be executed locally. Code must be valid Python code.</td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell prints out info about the current Spark sessions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1606801604877_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-32-197.us-west-2.compute.internal:20888/proxy/application_1606801604877_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-44-162.us-west-2.compute.internal:8042/node/containerlogs/container_1606801604877_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be \"no active sessions\" so far. If so, that's ok, you'll start one below. If you or someone else has run other sessions recently, you may receive a list of existing sessions.   \n",
    "\n",
    "If you receive an error such as \"Error sending http request and maximum retry encountered\", try restarting the kernel, then re-executing these cells. \n",
    "\n",
    "If you continue to see an error, check the configuration. Use a terminal to check that .sparkmagic/config.json on this SageMaker notebook instance has the correct IP address and port for the EMR cluster. Check that the EMR cluster has started correctly. Check that the EMR cluster's port is open and accessible to the SageMaker instance. Try accessing your EMR cluster on the Livy port (default 8998); you should see the Livy welcome page. Remember to restart the kernel after every change!\n",
    "\n",
    "Once this cell executes correctly, move on! \n",
    "\n",
    "The next cell should start a Spark session, and an application if needed. \n",
    "\n",
    "It'll also print out the IP address of the EMR cluster's master, and current setting of environment variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca416d752a5499bb4b437c6e2522a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip-172-31-32-197\n",
      "Linux-4.14.104-78.84.amzn1.x86_64-x86_64-with-glibc2.2.5\n",
      "('Spark home currently set to', '/usr/lib/spark')"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "# Print some characteristics of the remote system\n",
    "print(platform.node())\n",
    "print(platform.platform(aliased=0, terse=0))\n",
    "print(\"Spark home currently set to\", os.environ.get('SPARK_HOME', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the previous cell (it may take a minute or three to complete), you should see a message \"SparkSession available as 'spark'.\" \n",
    "\n",
    "If you don't: restart the Kernel for this notebook, and try running the above cells again.\n",
    "\n",
    "Now, run a basic Spark function. This cell shows how you can execute Spark parallelized functions on your EMR cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313bfd8e3bb74867baabdd9d5ee568b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version is: 2.4.0\n",
      "1000"
     ]
    }
   ],
   "source": [
    "# Run a basic Spark function, to show that's working\n",
    "# NOTE: This cell will likely throw an error the first time you run it ('TypeError: object of type 'NoneType' has no len()'). \n",
    "# This is due to a bug that showed up after 2.3.1 -> 2.3.2 upgrade of Spark.\n",
    "# It's also reported here: http://mail-archives.apache.org/mod_mbox/spark-issues/201811.mbox/%3CJIRA.13197858.1542041679000.391200.1542675600612@Atlassian.JIRA%3E\n",
    "# and here: http://mail-archives.apache.org/mod_mbox/livy-issues/201811.mbox/<JIRA.13199283.1542622344000.385221.1542622380848@Atlassian.JIRA>\n",
    "print(\"Spark version is: \" + sc.version)\n",
    "sc.parallelize(range(1000)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b36bcc4add45d0bee5f3b72dd62d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version is: 2.4.0\n",
      "1000"
     ]
    }
   ],
   "source": [
    "# Run a basic Spark function, to show that's working (and this time, it really should!)\n",
    "print(\"Spark version is: \" + sc.version)\n",
    "sc.parallelize(range(1000)).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can see the logs from this Spark task. This capability allows us to debug our Spark tasks without leaving the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdout: \n",
      "\n",
      "stderr: \n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1286)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1286)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1376)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2257)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "20/12/01 11:50:39 ERROR DAGScheduler: Failed to update accumulator 0 (org.apache.spark.api.python.PythonAccumulatorV2) for task 22\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n",
      "\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
      "\tat org.apache.spark.api.python.PythonAccumulatorV2.merge(PythonRDD.scala:648)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1286)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1286)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1376)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2257)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "20/12/01 11:50:39 ERROR DAGScheduler: Failed to update accumulator 0 (org.apache.spark.api.python.PythonAccumulatorV2) for task 23\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n",
      "\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
      "\tat org.apache.spark.api.python.PythonAccumulatorV2.merge(PythonRDD.scala:648)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1286)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1286)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1376)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2257)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "20/12/01 11:50:39 ERROR DAGScheduler: Failed to update accumulator 0 (org.apache.spark.api.python.PythonAccumulatorV2) for task 24\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n",
      "\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
      "\tat org.apache.spark.api.python.PythonAccumulatorV2.merge(PythonRDD.scala:648)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1286)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1286)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1376)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2257)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "20/12/01 11:50:39 ERROR DAGScheduler: Failed to update accumulator 0 (org.apache.spark.api.python.PythonAccumulatorV2) for task 25\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n",
      "\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
      "\tat org.apache.spark.api.python.PythonAccumulatorV2.merge(PythonRDD.scala:648)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1286)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1286)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1376)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2257)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "20/12/01 11:50:39 ERROR DAGScheduler: Failed to update accumulator 0 (org.apache.spark.api.python.PythonAccumulatorV2) for task 26\n",
      "java.net.SocketException: Broken pipe (Write failed)\n",
      "\tat java.net.SocketOutputStream.socketWrite0(Native Method)\n",
      "\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:111)\n",
      "\tat java.net.SocketOutputStream.write(SocketOutputStream.java:155)\n",
      "\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n",
      "\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n",
      "\tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n",
      "\tat org.apache.spark.api.python.PythonAccumulatorV2.merge(PythonRDD.scala:648)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1295)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1286)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)"
     ]
    }
   ],
   "source": [
    "%%logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Glue Data Catalog<a name='glue_access'></a> \n",
    "\n",
    "Let's switch to the topic at hand. \n",
    "\n",
    "The following examples run against the Glue 'glueredsage' database (or, the Glue database name you gave when executing the CloudFormation template). \n",
    "If you have not already done so, follow the instructions in the Glue tutorial under “Crawling the Sample Data Used in the Tutorials” (https://docs.aws.amazon.com/glue/latest/dg/dev-endpoint-tutorial-prerequisites.html#dev-endpoint-tutorial-prerequisites-crawl-data ), as outlined in the blog post instructions. You can stop once you’ve completed the steps to create the crawler, and can see the tables created by the crawler in your Data Catalog, containing metadata that the crawler retrieved.\n",
    "\n",
    "First, list the databases in the Glue Data Catalog. Then, list the tables, and the columns for the table you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "######################################################################################################\n",
    "# Update/Check the following variables with values for your environment\n",
    "# -- should have been correctly updated by the CF stack during deployment\n",
    "######################################################################################################\n",
    "\n",
    "glueDatabase = \"irisred\"\n",
    "region = \"us-west-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "!aws glue get-databases --output text | grep glueredsage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a couple of helper functions that will call the Glue Data Catalog, and format the most relevant parts of the response for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import boto3\n",
    "\n",
    "# Helper functions, to retrieve Glue Data Catalog information\n",
    "glue = boto3.client('glue', region_name=region)\n",
    "\n",
    "# List the tables in the given Glue database\n",
    "def get_glue_tables(gluedatabase):\n",
    "\t# From Glue/Hive metastore, get the table info.\n",
    "\ttbls = glue.get_tables(DatabaseName=gluedatabase)\n",
    "\ti = 0\n",
    "\tprint('{:5s} {:20s} {:30s}  {:20}'.format('', 'Database', 'TableName', 'TableType'))\n",
    "\tfor tbl in tbls['TableList']:\n",
    "\t\tprint('{:5s} {:20s} {:30s}  {:20}'.format(str(i), gluedatabase, tbl['Name'], tbl['TableType']))\n",
    "\t\ti += 1\n",
    "\n",
    "# List the columns of the named Glue table    \n",
    "def get_glue_table(gluedatabase, gluetblnm):\n",
    "\t# From Glue/Hive metastore, get the table info.\n",
    "\ttbldef = glue.get_table(DatabaseName=gluedatabase, Name=gluetblnm)\n",
    "\tprint('Table: ' + gluedatabase + '.' + gluetblnm + ': ' + tbldef['Table']['TableType'])\n",
    "\tif 'classification' in tbldef['Table']['Parameters'] and 'connectionName' in tbldef['Table']['Parameters']:\n",
    "\t\tprint('Classification: ' + tbldef['Table']['Parameters']['classification'] + '; connectionName: ' + tbldef['Table']['Parameters']['connectionName'])\n",
    "\telse:\n",
    "\t\tprint('Classification / connection information not available.')\n",
    "\ti = 0\n",
    "\tprint('{:5s} {:20s} {:20s} {:50s}'.format('','Column Name', 'Type', 'Comment'))\n",
    "\tfor col in tbldef['Table']['StorageDescriptor']['Columns']:\n",
    "\t\tcomment = ''\n",
    "\t\tif 'Comment' in col:\n",
    "\t\t\tcomment = col['Comment']    \n",
    "\t\tprint('{:5s} {:20s} {:20s} {:50s}'.format(str(i), col['Name'], col['Type'], comment))\n",
    "\t\ti += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the first helper function, to list the tables in the Glue database you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Database             TableName                       TableType           \n",
      "0     irisred              dev_public_category             EXTERNAL_TABLE      \n",
      "1     irisred              dev_public_date                 EXTERNAL_TABLE      \n",
      "2     irisred              dev_public_event                EXTERNAL_TABLE      \n",
      "3     irisred              dev_public_listing              EXTERNAL_TABLE      \n",
      "4     irisred              dev_public_sales                EXTERNAL_TABLE      \n",
      "5     irisred              dev_public_users                EXTERNAL_TABLE      \n",
      "6     irisred              dev_public_venue                EXTERNAL_TABLE      \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "get_glue_tables(glueDatabase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not receive a list of the Redshift tables from the above command, check that you've run the Glue-Redshift crawler. Use the AWS Glue console to check that there are, in fact, tables in that database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a chosen table, list the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: irisred.dev_public_category: EXTERNAL_TABLE\n",
      "Classification: redshift; connectionName: rs-glue\n",
      "      Column Name          Type                 Comment                                           \n",
      "0     catid                smallint                                                               \n",
      "1     catname              string                                                                 \n",
      "2     catdesc              string                                                                 \n",
      "3     catgroup             string                                                                 \n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "tblnme = 'dev_public_category'\n",
    "get_glue_table(glueDatabase, tblnme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this table has a classification of \"redshift\", and it's connection (GlueRedshiftConnection). So, to access the data, you'll need to read the data from Redshift. The GlueRedshiftConnection will contain the information you need to connect to Redshift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Redshift data<a name='redshift_access'></a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you wish to retrieve a table (or, part of a table, or the results of a SQL query), for futher specialized processing. Generally speaking, you want to do as much as you can with the data in place, and only retrieve the subset of data you need to perform actions on that cannot be performed in SQL.  \n",
    "\n",
    "If the data is small, you can retrieve directly into your notebook. But since this data is likely large, you'll retrieve it into a data frame in Spark on EMR so you can process it further there.\n",
    "\n",
    "First, set up the variables on the remote cluster. Note that these variables are separate from those used in your local environment, and that the variables are not communicated between the two environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1543789425048d082286274a0f70103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################################################\n",
    "# Update/Check the following variables with values for your environment\n",
    "# -- should have been correctly updated by the CF stack during deployment\n",
    "######################################################################################################\n",
    "# Redshift IAM Copy Role, attached to the Redshift cluster you're trying to access.\n",
    "iamcopyrole = 'arn:aws:iam::029498593638:role/rs-cluster-RedshiftIamCopyRole-1PEZ76PIOEXKS'\n",
    "glueDatabase = 'irisred'\n",
    "# Tablename here is the Glue table\n",
    "# NOTE that they can't have '-' in them; it's ok by Glue, but not for Hive\n",
    "tblname = 'dev_public_category'\n",
    "region = 'us-west-2'\n",
    "s3Bucket = 'sagemakerworkshop-log-dsc-smlab'\n",
    "# Temp directory; should have lifecycle policy to delete temp files 'frequently'. \n",
    "# Remember to use the format: 's3a://<bucket>/<prefix>/'\n",
    "tempS3Dir = 's3a://' + s3Bucket + '/temp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up helper functions to retrieve Redshift connection information from the Glue Data Catalog, and to read the table from Redshift into EMR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acc2bec02db44a5baa3bce4ca86c628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sql_context = SQLContext(sc)\n",
    "\n",
    "def get_redshift_connection_info(gluedatabase, gluetblname, awsregion):\n",
    "\t# From Glue/Hive metastore, get the table info.\n",
    "\tclient = boto3.client('glue', region_name=awsregion)\n",
    "\ttbl = client.get_table(DatabaseName=gluedatabase, Name=gluetblname)\n",
    "\tparms = tbl['Table']['StorageDescriptor']['Parameters']\n",
    "\tclassn = parms['classification']\n",
    "\tconn = parms['connectionName']\n",
    "\tlocation = tbl['Table']['StorageDescriptor']['Location']\n",
    "\tif classn <> 'redshift':\n",
    "\t\tprint('This table is not a Redshift table; it is of type ' + str(classn))\n",
    "\t\treturn None\n",
    "\t# THEN: Get connection data.\n",
    "\tresponse = client.get_connection(Name=conn)\n",
    "\tconnp = response['Connection']['ConnectionProperties']\n",
    "\turl = connp['JDBC_CONNECTION_URL'] + '?user=' + connp['USERNAME'] + '&password=' + connp['PASSWORD']\n",
    "\tprint('Connection info:', location, connp['JDBC_CONNECTION_URL'])\n",
    "\treturn (url, location)\n",
    "\n",
    "def get_redshift_data(gluedatabase, gluetblname, awsregion, tempS3Dir, iamcopyrole):\n",
    "\t(url, location) = get_redshift_connection_info(gluedatabase, gluetblname, awsregion)\n",
    "\ttblbits = location.split('.')\n",
    "\trstblname = tblbits[1] + '.' + tblbits[2]    \n",
    "\tprint('Getting dataframe:', gluetblname, '-->', rstblname)   \n",
    "\t# THEN finally, get the data.\n",
    "\tdf = sql_context.read.format('com.databricks.spark.redshift').option('aws_iam_role',iamcopyrole).option('tempdir', tempS3Dir).option('url', url).option('dbtable', rstblname).load() \n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this code retrieves the table from Redshift to S3, then into EMR, and finally into a data frame that you can access locally. This is all done for you by the Spark Redshift driver you're using here.\n",
    "\n",
    "The '-o' parameter gives the data frame name. You can take a subset or sample of the rows, using the Livy -r, -m and -n options described in the Help above. As it's a large dataset, here you'll first retrieve a small subset to review. (It may take a few minutes to retrieve the data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119d4f1f9af6446391aefa88fb42b49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection info:', u'dev.public.category', u'jdbc:redshift://rs-cluster-redshiftcluster-8gdu5k60mj60.cocm2vzetawj.us-west-2.redshift.amazonaws.com:5439/dev')\n",
      "('Getting dataframe:', 'dev_public_category', '-->', u'public.category')\n",
      "+-----+--------+---------+------------------------------------------+\n",
      "|catid|catgroup|catname  |catdesc                                   |\n",
      "+-----+--------+---------+------------------------------------------+\n",
      "|1    |Sports  |MLB      |Major League Baseball                     |\n",
      "|7    |Shows   |Plays    |All non-musical theatre                   |\n",
      "|5    |Sports  |MLS      |Major League Soccer                       |\n",
      "|9    |Concerts|Pop      |All rock and pop music concerts           |\n",
      "|6    |Shows   |Musicals |Musical theatre                           |\n",
      "|10   |Concerts|Jazz     |All jazz singers and bands                |\n",
      "|3    |Sports  |NFL      |National Football League                  |\n",
      "|8    |Shows   |Opera    |All opera and light opera                 |\n",
      "|2    |Sports  |NHL      |National Hockey League                    |\n",
      "|4    |Sports  |NBA      |National Basketball Association           |\n",
      "|11   |Concerts|Classical|All symphony, concerto, and choir concerts|\n",
      "+-----+--------+---------+------------------------------------------+"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7f6933c5be4c558e8d906d8d0febf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o category -n 25\n",
    "\n",
    "# This next command gets the table into the dataframe 'users', on the Spark cluster\n",
    "category = get_redshift_data(glueDatabase, tblname, region, tempS3Dir, iamcopyrole)\n",
    "category.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a SQL to specify a subset of the data; or, to join, aggregate and filter data on the Redshift cluster. The helper function and small example below shows you how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e773190f03b48afbb24c54ad204ef30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_redshift_query(url, tempS3Dir, sqlquery):\n",
    "\tdf = sql_context.read.format('com.databricks.spark.redshift').option('tempdir', tempS3Dir).option('url', url).option('query', sqlquery).load()\n",
    "\tprint('Getting dataframe:', sqlquery)    \n",
    "\treturn df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, you can add SQL statements, to join, filter or aggregate the Redshift data prior to unloading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896176f10b894bfa8648f97fee34a14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection info:', u'dev.public.category', u'jdbc:redshift://rs-cluster-redshiftcluster-8gdu5k60mj60.cocm2vzetawj.us-west-2.redshift.amazonaws.com:5439/dev')\n",
      "('Getting dataframe:', 'SELECT distinct u.userid, u.city, u.state, \\nNVL(u.likebroadway, false) as likebroadway, NVL(u.likeclassical, false) as likeclassical, NVL(u.likeconcerts, false) as likeconcerts, \\nNVL(u.likejazz, false) as likejazz, NVL(u.likemusicals, false) as likemusicals, NVL(u.likeopera, false) as likeopera, NVL(u.likerock, false) as likerock,\\nNVL(u.likesports, false) as likesports, NVL(u.liketheatre, false) as liketheatre, NVL(u.likevegas, false) as likevegas, \\nd.caldate, d.day, d.month, d.year, d.week, d.holiday,\\ns.pricepaid, s.qtysold, -- s.salesid, s.listid, s.saletime, s.sellerid, s.commission\\ne.eventname, -- e.venueid, e.catid, e.eventid, \\nc.catgroup, c.catname,\\nv.venuecity, v.venuename, v.venuestate, v.venueseats\\nFROM  users u, sales s, event e, venue v, date d, category c\\nWHERE u.userid = s.buyerid and s.dateid = e.dateid and s.eventid = e.eventid and e.venueid = v.venueid \\n    and e.dateid = d.dateid and e.catid = c.catid    \\n')\n",
      "+------+--------------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+-------+-------------+--------------------+----------+----------+\n",
      "|userid|          city|state|likebroadway|likeclassical|likeconcerts|likejazz|likemusicals|likeopera|likerock|likesports|liketheatre|likevegas|   caldate|day|month|year|week|holiday|pricepaid|qtysold|           eventname|catgroup|catname|    venuecity|           venuename|venuestate|venueseats|\n",
      "+------+--------------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+-------+-------------+--------------------+----------+----------+\n",
      "| 29839|     Covington|   MA|        true|        false|       false|   false|        true|    false|   false|      true|       true|    false|2008-02-18| TU|  FEB|2008|   8|  false|   302.00|      2|    Juan Luis Guerra|Concerts|    Pop|     Portland|         Rose Garden|        OR|         0|\n",
      "| 10913|   Idaho Falls|   NL|       false|        false|        true|   false|       false|    false|   false|     false|      false|    false|2008-03-01| SA|  MAR|2008|  10|  false|   531.00|      1|          Joe Cocker|Concerts|    Pop|      Atlanta|        Turner Field|        GA|     50091|\n",
      "| 40411|        Durham|   MI|       false|        false|        true|   false|        true|     true|   false|     false|      false|    false|2008-08-08| FR|  AUG|2008|  32|  false|   102.00|      1|Southside Johnny ...|Concerts|    Pop|      Toronto|       Rogers Centre|        ON|     50516|\n",
      "| 43381|South Portland|   QC|       false|         true|       false|   false|        true|     true|   false|     false|      false|     true|2008-09-04| TH|  SEP|2008|  36|  false|   285.00|      1|            November|   Shows|  Plays|New York City|Brooks Atkinson T...|        NY|         0|\n",
      "| 45552|       Methuen|   ME|        true|        false|        true|   false|       false|     true|   false|     false|      false|    false|2008-11-25| TU|  NOV|2008|  48|  false|   432.00|      2|         Wallflowers|Concerts|    Pop|   Charleston|North Charleston ...|        SC|         0|\n",
      "+------+--------------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+-------+-------------+--------------------+----------+----------+\n",
      "only showing top 5 rows"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22bde30b0e8452f86d9ed770d9044e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o userevents\n",
    "# First, get the connection information for Redshift, using a table that's stored in that cluster\n",
    "(url, tblbits) = get_redshift_connection_info(glueDatabase, tblname, region)\n",
    "\n",
    "sqlquery = \"\"\"SELECT distinct u.userid, u.city, u.state, \n",
    "NVL(u.likebroadway, false) as likebroadway, NVL(u.likeclassical, false) as likeclassical, NVL(u.likeconcerts, false) as likeconcerts, \n",
    "NVL(u.likejazz, false) as likejazz, NVL(u.likemusicals, false) as likemusicals, NVL(u.likeopera, false) as likeopera, NVL(u.likerock, false) as likerock,\n",
    "NVL(u.likesports, false) as likesports, NVL(u.liketheatre, false) as liketheatre, NVL(u.likevegas, false) as likevegas, \n",
    "d.caldate, d.day, d.month, d.year, d.week, d.holiday,\n",
    "s.pricepaid, s.qtysold, -- s.salesid, s.listid, s.saletime, s.sellerid, s.commission\n",
    "e.eventname, -- e.venueid, e.catid, e.eventid, \n",
    "c.catgroup, c.catname,\n",
    "v.venuecity, v.venuename, v.venuestate, v.venueseats\n",
    "FROM  users u, sales s, event e, venue v, date d, category c\n",
    "WHERE u.userid = s.buyerid and s.dateid = e.dateid and s.eventid = e.eventid and e.venueid = v.venueid \n",
    "    and e.dateid = d.dateid and e.catid = c.catid    \n",
    "\"\"\"\n",
    "# Execute the query and retrieve data into the dataframe 'userevents', on the Spark cluster\n",
    "userevents = get_redshift_query(url, tempS3Dir, sqlquery)\n",
    "userevents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Data on the Local Notebook<a name='local_access'></a>\n",
    "\n",
    "Next, let's check the characteristics of the local system. Check the IP address printed below; it should be different from the IP address of the EMR system above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x86_64\n",
      "ip-172-16-87-213\n",
      "Linux-4.14.200-116.320.amzn1.x86_64-x86_64-with-glibc2.9\n",
      "/home/ec2-user/SageMaker\n",
      "lost+found  Using_SageMaker_Notebooks_to_access_Redshift_via_Glue.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "# Print some characteristics of the local system\n",
    "import platform\n",
    "print(platform.machine())\n",
    "print(platform.node())\n",
    "print(platform.platform(aliased=0, terse=0))\n",
    "\n",
    "# Print some local data from the OS: current path, and files in the current directory\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, show basic information about the query results, but displaying them the local system. Note that it's now a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 28 columns):\n",
      "userid           2500 non-null int64\n",
      "city             2500 non-null object\n",
      "state            2500 non-null object\n",
      "likebroadway     2500 non-null bool\n",
      "likeclassical    2500 non-null bool\n",
      "likeconcerts     2500 non-null bool\n",
      "likejazz         2500 non-null bool\n",
      "likemusicals     2500 non-null bool\n",
      "likeopera        2500 non-null bool\n",
      "likerock         2500 non-null bool\n",
      "likesports       2500 non-null bool\n",
      "liketheatre      2500 non-null bool\n",
      "likevegas        2500 non-null bool\n",
      "caldate          2500 non-null datetime64[ns]\n",
      "day              2500 non-null object\n",
      "month            2500 non-null object\n",
      "year             2500 non-null int64\n",
      "week             2500 non-null int64\n",
      "holiday          2500 non-null bool\n",
      "pricepaid        2500 non-null float64\n",
      "qtysold          2500 non-null int64\n",
      "eventname        2500 non-null object\n",
      "catgroup         2500 non-null object\n",
      "catname          2500 non-null object\n",
      "venuecity        2500 non-null object\n",
      "venuename        2500 non-null object\n",
      "venuestate       2500 non-null object\n",
      "venueseats       2412 non-null float64\n",
      "dtypes: bool(11), datetime64[ns](1), float64(2), int64(4), object(10)\n",
      "memory usage: 359.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>likebroadway</th>\n",
       "      <th>likeclassical</th>\n",
       "      <th>likeconcerts</th>\n",
       "      <th>likejazz</th>\n",
       "      <th>likemusicals</th>\n",
       "      <th>likeopera</th>\n",
       "      <th>likerock</th>\n",
       "      <th>...</th>\n",
       "      <th>holiday</th>\n",
       "      <th>pricepaid</th>\n",
       "      <th>qtysold</th>\n",
       "      <th>eventname</th>\n",
       "      <th>catgroup</th>\n",
       "      <th>catname</th>\n",
       "      <th>venuecity</th>\n",
       "      <th>venuename</th>\n",
       "      <th>venuestate</th>\n",
       "      <th>venueseats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29839</td>\n",
       "      <td>Covington</td>\n",
       "      <td>MA</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Juan Luis Guerra</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Rose Garden</td>\n",
       "      <td>OR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10913</td>\n",
       "      <td>Idaho Falls</td>\n",
       "      <td>NL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Joe Cocker</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Turner Field</td>\n",
       "      <td>GA</td>\n",
       "      <td>50091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40411</td>\n",
       "      <td>Durham</td>\n",
       "      <td>MI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Southside Johnny &amp; the Asbury Jukes</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Rogers Centre</td>\n",
       "      <td>ON</td>\n",
       "      <td>50516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43381</td>\n",
       "      <td>South Portland</td>\n",
       "      <td>QC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1</td>\n",
       "      <td>November</td>\n",
       "      <td>Shows</td>\n",
       "      <td>Plays</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Brooks Atkinson Theatre</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45552</td>\n",
       "      <td>Methuen</td>\n",
       "      <td>ME</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>432.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Wallflowers</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>North Charleston Coliseum</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid            city state  likebroadway  likeclassical  likeconcerts  \\\n",
       "0   29839       Covington    MA          True          False         False   \n",
       "1   10913     Idaho Falls    NL         False          False          True   \n",
       "2   40411          Durham    MI         False          False          True   \n",
       "3   43381  South Portland    QC         False           True         False   \n",
       "4   45552         Methuen    ME          True          False          True   \n",
       "\n",
       "   likejazz  likemusicals  likeopera  likerock     ...      holiday  \\\n",
       "0     False          True      False     False     ...        False   \n",
       "1     False         False      False     False     ...        False   \n",
       "2     False          True       True     False     ...        False   \n",
       "3     False          True       True     False     ...        False   \n",
       "4     False         False       True     False     ...        False   \n",
       "\n",
       "   pricepaid  qtysold                            eventname  catgroup catname  \\\n",
       "0      302.0        2                     Juan Luis Guerra  Concerts     Pop   \n",
       "1      531.0        1                           Joe Cocker  Concerts     Pop   \n",
       "2      102.0        1  Southside Johnny & the Asbury Jukes  Concerts     Pop   \n",
       "3      285.0        1                             November     Shows   Plays   \n",
       "4      432.0        2                          Wallflowers  Concerts     Pop   \n",
       "\n",
       "       venuecity                  venuename  venuestate  venueseats  \n",
       "0       Portland                Rose Garden          OR         0.0  \n",
       "1        Atlanta               Turner Field          GA     50091.0  \n",
       "2        Toronto              Rogers Centre          ON     50516.0  \n",
       "3  New York City    Brooks Atkinson Theatre          NY         0.0  \n",
       "4     Charleston  North Charleston Coliseum          SC         0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>pricepaid</th>\n",
       "      <th>qtysold</th>\n",
       "      <th>venueseats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500.00000</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24016.99800</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>28.801200</td>\n",
       "      <td>639.117600</td>\n",
       "      <td>1.998400</td>\n",
       "      <td>14891.921642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14409.61945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.996258</td>\n",
       "      <td>883.834788</td>\n",
       "      <td>1.068669</td>\n",
       "      <td>26242.698322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>52.00000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11554.50000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23369.50000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36605.25000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49984.00000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>9912.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>91704.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userid    year         week    pricepaid      qtysold  \\\n",
       "count   2500.00000  2500.0  2500.000000  2500.000000  2500.000000   \n",
       "mean   24016.99800  2008.0    28.801200   639.117600     1.998400   \n",
       "std    14409.61945     0.0    13.996258   883.834788     1.068669   \n",
       "min       52.00000  2008.0     1.000000    20.000000     1.000000   \n",
       "25%    11554.50000  2008.0    17.000000   195.000000     1.000000   \n",
       "50%    23369.50000  2008.0    29.000000   376.000000     2.000000   \n",
       "75%    36605.25000  2008.0    41.000000   770.000000     2.000000   \n",
       "max    49984.00000  2008.0    53.000000  9912.000000     8.000000   \n",
       "\n",
       "         venueseats  \n",
       "count   2412.000000  \n",
       "mean   14891.921642  \n",
       "std    26242.698322  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%    36660.000000  \n",
       "max    91704.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Oshkosh            9\n",
       "Rancho Cordova     9\n",
       "Fajardo            8\n",
       "Concord            8\n",
       "Pass Christian     8\n",
       "Peabody            8\n",
       "Alexandria         7\n",
       "Olean              7\n",
       "Toledo             7\n",
       "Lynwood            7\n",
       "Twin Falls         7\n",
       "Roanoke            7\n",
       "Columbia           7\n",
       "Baldwin Park       7\n",
       "Elko               7\n",
       "Plattsburgh        7\n",
       "Ocean City         7\n",
       "Lakewood           7\n",
       "Champaign          6\n",
       "Fountain Valley    6\n",
       "Redding            6\n",
       "Hopkinsville       6\n",
       "Rolling Hills      6\n",
       "Starkville         6\n",
       "Visalia            6\n",
       "Peekskill          6\n",
       "Longview           6\n",
       "Healdsburg         6\n",
       "Brookings          6\n",
       "Yukon              6\n",
       "                  ..\n",
       "Sandpoint          1\n",
       "New Rochelle       1\n",
       "Cincinnati         1\n",
       "Tok                1\n",
       "Mason City         1\n",
       "Redondo Beach      1\n",
       "Wynne              1\n",
       "Sheridan           1\n",
       "Rosemead           1\n",
       "Coatesville        1\n",
       "New Castle         1\n",
       "Spokane Valley     1\n",
       "Mandan             1\n",
       "Corry              1\n",
       "Muskegon           1\n",
       "Atwater            1\n",
       "Racine             1\n",
       "Missoula           1\n",
       "Quincy             1\n",
       "Apple Valley       1\n",
       "Canton             1\n",
       "Roseville          1\n",
       "Tucson             1\n",
       "Cape Girardeau     1\n",
       "Taylorsville       1\n",
       "Mayagez            1\n",
       "Lancaster          1\n",
       "Santa Fe           1\n",
       "Kahului            1\n",
       "Agoura Hills       1\n",
       "Name: city, Length: 936, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "userevents.info()\n",
    "\n",
    "# show the top few rows\n",
    "display(userevents.head())\n",
    "\n",
    "# describe the data object\n",
    "display(userevents.describe())\n",
    "\n",
    "# Summarize the categorical field species \n",
    "display(userevents.city.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802d55f55f89485a9a0982bf21e11852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+-------+-------------+--------------------+----------+----------+\n",
      "|userid|      city|state|likebroadway|likeclassical|likeconcerts|likejazz|likemusicals|likeopera|likerock|likesports|liketheatre|likevegas|   caldate|day|month|year|week|holiday|pricepaid|qtysold|           eventname|catgroup|catname|    venuecity|           venuename|venuestate|venueseats|\n",
      "+------+----------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+-------+-------------+--------------------+----------+----------+\n",
      "|   983|    Pierre|   AB|       false|        false|       false|   false|       false|    false|   false|     false|      false|    false|2008-06-19| TH|  JUN|2008|  25|  false|  1460.00|      4|         Demi Lovato|Concerts|    Pop|       Carson|The Home Depot Ce...|        CA|         0|\n",
      "| 39085|   Norwalk|   MB|        true|        false|       false|   false|       false|    false|   false|     false|      false|     true|2008-09-14| SU|  SEP|2008|  38|  false|   184.00|      1|Toad The Wet Spro...|Concerts|    Pop| Philadelphia|Lincoln Financial...|        PA|     68532|\n",
      "| 27399|Pittsfield|   QC|       false|        false|       false|   false|        true|    false|   false|     false|       true|    false|2008-10-17| FR|  OCT|2008|  42|  false|  1212.00|      4|             Othello|   Shows|  Plays|New York City|Al Hirschfeld The...|        NY|         0|\n",
      "| 17474|  Amesbury|   ON|       false|         true|       false|   false|       false|    false|   false|     false|       true|    false|2008-11-30| SU|  NOV|2008|  49|  false|    65.00|      1|             Electra|   Shows|  Plays|New York City|     Shubert Theatre|        NY|         0|\n",
      "| 29839| Covington|   MA|        true|        false|       false|   false|        true|    false|   false|      true|       true|    false|2008-02-18| TU|  FEB|2008|   8|  false|   302.00|      2|    Juan Luis Guerra|Concerts|    Pop|     Portland|         Rose Garden|        OR|         0|\n",
      "+------+----------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+-------+-------------+--------------------+----------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "userevents.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>likebroadway</th>\n",
       "      <th>likeclassical</th>\n",
       "      <th>likeconcerts</th>\n",
       "      <th>likejazz</th>\n",
       "      <th>likemusicals</th>\n",
       "      <th>likeopera</th>\n",
       "      <th>likerock</th>\n",
       "      <th>...</th>\n",
       "      <th>holiday</th>\n",
       "      <th>pricepaid</th>\n",
       "      <th>qtysold</th>\n",
       "      <th>eventname</th>\n",
       "      <th>catgroup</th>\n",
       "      <th>catname</th>\n",
       "      <th>venuecity</th>\n",
       "      <th>venuename</th>\n",
       "      <th>venuestate</th>\n",
       "      <th>venueseats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>26466</td>\n",
       "      <td>Barrow</td>\n",
       "      <td>PA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mamma Mia!</td>\n",
       "      <td>Shows</td>\n",
       "      <td>Musicals</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Paris MGM Grand</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>44480</td>\n",
       "      <td>Normal</td>\n",
       "      <td>MS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2493.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Anita Baker</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Saratoga Springs</td>\n",
       "      <td>Saratoga Springs Performing Arts Center</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>46301</td>\n",
       "      <td>Sharon</td>\n",
       "      <td>OH</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>618.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Wyclef Jean</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Denver</td>\n",
       "      <td>INVESCO Field</td>\n",
       "      <td>CO</td>\n",
       "      <td>76125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19555</td>\n",
       "      <td>West Memphis</td>\n",
       "      <td>AB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>222.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>Shows</td>\n",
       "      <td>Opera</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Lyric Opera House</td>\n",
       "      <td>IL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>5815</td>\n",
       "      <td>Agawam</td>\n",
       "      <td>PA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Little River Band</td>\n",
       "      <td>Concerts</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>M&amp;T Bank Stadium</td>\n",
       "      <td>MD</td>\n",
       "      <td>70107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid          city state  likebroadway  likeclassical  likeconcerts  \\\n",
       "564    26466        Barrow    PA         False          False         False   \n",
       "1753   44480        Normal    MS         False           True         False   \n",
       "2493   46301        Sharon    OH         False          False         False   \n",
       "33     19555  West Memphis    AB         False          False         False   \n",
       "1351    5815        Agawam    PA         False          False         False   \n",
       "\n",
       "      likejazz  likemusicals  likeopera  likerock     ...      holiday  \\\n",
       "564      False         False      False     False     ...        False   \n",
       "1753     False         False       True     False     ...        False   \n",
       "2493     False         False      False     False     ...        False   \n",
       "33       False         False      False     False     ...        False   \n",
       "1351     False         False      False     False     ...        False   \n",
       "\n",
       "      pricepaid  qtysold          eventname  catgroup   catname  \\\n",
       "564        29.0        1         Mamma Mia!     Shows  Musicals   \n",
       "1753     2493.0        1        Anita Baker  Concerts       Pop   \n",
       "2493      618.0        2        Wyclef Jean  Concerts       Pop   \n",
       "33        222.0        2             Carmen     Shows     Opera   \n",
       "1351      290.0        1  Little River Band  Concerts       Pop   \n",
       "\n",
       "             venuecity                                venuename  venuestate  \\\n",
       "564          Las Vegas                          Paris MGM Grand          NV   \n",
       "1753  Saratoga Springs  Saratoga Springs Performing Arts Center          NY   \n",
       "2493            Denver                            INVESCO Field          CO   \n",
       "33             Chicago                        Lyric Opera House          IL   \n",
       "1351         Baltimore                         M&T Bank Stadium          MD   \n",
       "\n",
       "      venueseats  \n",
       "564          NaN  \n",
       "1753         0.0  \n",
       "2493     76125.0  \n",
       "33           0.0  \n",
       "1351     70107.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "userevents.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can mix and match between using local and remote. The next cell transforms the dataframe on Spark, converting a categorical field into a one-hot vector for use by Spark ML libraries. Below, this field will be used to look at correlations between the user \"likes\" and the types of events they attended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27cd277a5ce4db6b6c2bbe5b3c80b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+--------+-------------+--------------------+----------+----------+--------+-------------+\n",
      "|userid|         city|state|likebroadway|likeclassical|likeconcerts|likejazz|likemusicals|likeopera|likerock|likesports|liketheatre|likevegas|   caldate|day|month|year|week|holiday|pricepaid|qtysold|           eventname|catgroup| catname|    venuecity|           venuename|venuestate|venueseats|catIndex|       catVec|\n",
      "+------+-------------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+--------+-------------+--------------------+----------+----------+--------+-------------+\n",
      "| 42783|    Manhattan|   RI|       false|        false|       false|   false|        true|    false|   false|     false|      false|     true|2008-05-11| SU|  MAY|2008|  20|  false|   346.00|      2|           Third Day|Concerts|     Pop|      Toronto|           BMO Field|        ON|         0|     0.0|(4,[0],[1.0])|\n",
      "| 23988|Stevens Point|   YT|       false|        false|       false|   false|       false|    false|    true|     false|       true|    false|2008-08-20| WE|  AUG|2008|  34|  false|   982.00|      2|           Joan Baez|Concerts|     Pop|       Dallas|American Airlines...|        TX|         0|     0.0|(4,[0],[1.0])|\n",
      "| 30734|        Olean|   OH|       false|        false|       false|   false|       false|    false|    true|     false|       true|    false|2008-12-01| MO|  DEC|2008|  49|  false|   111.00|      1|      Regina Spektor|Concerts|     Pop|    Charlotte|Bank of America S...|        NC|     73298|     0.0|(4,[0],[1.0])|\n",
      "|  8882|  Farmer City|   NB|        true|        false|        true|    true|       false|     true|    true|     false|      false|    false|2008-03-16| SU|  MAR|2008|  12|  false|   334.00|      2|          Mamma Mia!|   Shows|Musicals|New York City|Bernard B. Jacobs...|        NY|         0|     2.0|(4,[2],[1.0])|\n",
      "| 40900|  Gainesville|   NT|       false|        false|       false|    true|        true|    false|    true|     false|      false|    false|2008-03-26| WE|  MAR|2008|  13|  false|   730.00|      2|             Extreme|Concerts|     Pop|   Washington|         RFK Stadium|        DC|         0|     0.0|(4,[0],[1.0])|\n",
      "| 31630|      Radford|   KY|       false|        false|       false|   false|       false|     true|   false|      true|      false|    false|2008-10-21| TU|  OCT|2008|  43|  false|   848.00|      4|         Bad Company|Concerts|     Pop|      Chicago|       Soldier Field|        IL|     63000|     0.0|(4,[0],[1.0])|\n",
      "|  4755|    Texarkana|   NH|       false|        false|        true|   false|        true|    false|    true|     false|      false|    false|2008-01-10| FR|  JAN|2008|   2|  false|   418.00|      1|        The 39 Steps|   Shows|   Plays|New York City|Lincoln Center fo...|        NY|         0|     1.0|(4,[1],[1.0])|\n",
      "| 15257|     Rockford|   MB|       false|        false|       false|    true|       false|     true|   false|      true|      false|    false|2008-03-10| MO|  MAR|2008|  11|  false|   450.00|      2|             Electra|   Shows|   Plays|New York City|Eugene O'Neill Th...|        NY|         0|     1.0|(4,[1],[1.0])|\n",
      "| 37330|         Mesa|   DC|       false|        false|       false|    true|        true|    false|   false|     false|       true|    false|2008-04-12| SA|  APR|2008|  16|  false|   262.00|      2|A Midsummer Night...|   Shows|   Plays|New York City|American Airlines...|        NY|         0|     1.0|(4,[1],[1.0])|\n",
      "| 36090|   Villa Park|   YT|       false|        false|       false|   false|       false|    false|   false|     false|       true|    false|2008-04-26| SA|  APR|2008|  18|  false|  1292.00|      4|      Tower of Power|Concerts|     Pop|      Houston|       Toyota Center|        TX|         0|     0.0|(4,[0],[1.0])|\n",
      "| 41311|     Cortland|   MO|       false|        false|       false|    true|       false|    false|   false|     false|      false|    false|2008-05-18| SU|  MAY|2008|  21|  false|   334.00|      1|New Kids on the B...|Concerts|     Pop|      Sunrise| BankAtlantic Center|        FL|         0|     0.0|(4,[0],[1.0])|\n",
      "| 45468|      Phoenix|   CO|       false|        false|       false|   false|       false|    false|    true|     false|      false|    false|2008-06-07| SA|  JUN|2008|  24|  false|   305.00|      1|     Brooks and Dunn|Concerts|     Pop|San Francisco|           AT&T Park|        CA|     41503|     0.0|(4,[0],[1.0])|\n",
      "| 42662|      Lansing|   DE|       false|        false|       false|    true|       false|    false|   false|     false|       true|    false|2008-09-24| WE|  SEP|2008|  39|  false|   748.00|      2|              Grease|   Shows|Musicals|New York City|        Cort Theatre|        NY|         0|     2.0|(4,[2],[1.0])|\n",
      "| 23797|   New London|   MA|       false|         true|       false|   false|       false|     true|   false|     false|      false|    false|2008-12-04| TH|  DEC|2008|  49|  false|  1472.00|      4|    Spring Awakening|   Shows|   Plays|New York City|  Neil Simon Theatre|        NY|         0|     1.0|(4,[1],[1.0])|\n",
      "|  3359|   Torrington|   RI|       false|        false|        true|   false|       false|     true|   false|      true|      false|    false|2008-12-16| TU|  DEC|2008|  51|  false|   211.00|      1|August: Osage County|   Shows|   Plays|     Pasadena|  Pasadena Playhouse|        CA|         0|     1.0|(4,[1],[1.0])|\n",
      "| 29049|       Bandon|   IA|       false|        false|       false|   false|       false|    false|   false|      true|      false|    false|2008-02-12| WE|  FEB|2008|   7|  false|   191.00|      1|  Tristan und Isolde|   Shows|   Opera|    Galveston|Grand 1894 Opera ...|        TX|         0|     3.0|(4,[3],[1.0])|\n",
      "|  6044|      Ardmore|   QC|        true|        false|        true|   false|       false|    false|    true|      true|       true|    false|2008-05-29| TH|  MAY|2008|  22|  false|   367.00|      1|Creedence Clearwa...|Concerts|     Pop|       Dayton|  E.J. Nutter Center|        OH|         0|     0.0|(4,[0],[1.0])|\n",
      "| 20780|    Claremore|   VT|       false|        false|       false|   false|        true|     true|    true|     false|      false|    false|2008-07-01| TU|  JUL|2008|  27|  false|   146.00|      2|          Miss Julie|   Shows|   Plays|New York City|Lincoln Center fo...|        NY|         0|     1.0|(4,[1],[1.0])|\n",
      "| 19320|      Jackson|   MN|       false|        false|        true|   false|        true|     true|   false|     false|      false|    false|2008-07-23| WE|  JUL|2008|  30|  false|   928.00|      4| Glengarry Glen Ross|   Shows|   Plays|New York City|Eugene O'Neill Th...|        NY|         0|     1.0|(4,[1],[1.0])|\n",
      "| 10939|      Detroit|   BC|       false|        false|       false|   false|       false|    false|   false|     false|      false|    false|2008-12-25| TH|  DEC|2008|  52|   true|   670.00|      2|La Cenerentola (C...|   Shows|   Opera|      Chicago|   Lyric Opera House|        IL|         0|     3.0|(4,[3],[1.0])|\n",
      "+------+-------------+-----+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+----------+---+-----+----+----+-------+---------+-------+--------------------+--------+--------+-------------+--------------------+----------+----------+--------+-------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "#from pyspark.ml import Pipeline\n",
    "#from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler\n",
    "#from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "\n",
    "# city, state, day, eventname, venuecity, venuename, venuestate, catname are all text, categorical fields.\n",
    "# Convert needed text fields to one-hot vectors as needed for downstream calcs\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"catname\", outputCol=\"catIndex\")\n",
    "model = stringIndexer.fit(userevents)\n",
    "indexed = model.transform(userevents)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"catIndex\", outputCol=\"catVec\", dropLast=False)\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384d294192fc44a189b9d05c0c8435f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: u'Pop', 1: u'Plays', 2: u'Musicals', 3: u'Opera'}"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "# Get/Save the mapping of categorical values used in the one-hot vector encoding for (what will become) columns\n",
    "meta = [\n",
    "    f.metadata for f in indexed.schema.fields if f.name == \"catIndex\"\n",
    "]\n",
    "theCorrCols = meta[0][\"ml_attr\"][\"vals\"]\n",
    "colValues = dict(enumerate(meta[0][\"ml_attr\"][\"vals\"]))\n",
    "colValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although there were more categories available, only 4 are represented in the merged event data. Perhaps no events of the other types were attended? Something to research in the data! But for now, go ahead with just the available data. Extract the \"likes\" columns and the one-hot vector just built and transform into a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862d905141d843e5aae62e18a2b688e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+-------------+---------------------------------------------+\n",
      "|likebroadway|likeclassical|likeconcerts|likejazz|likemusicals|likeopera|likerock|likesports|liketheatre|likevegas|catVec       |features                                     |\n",
      "+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+-------------+---------------------------------------------+\n",
      "|false       |false        |false       |false   |false       |false    |false   |false     |false      |false    |(4,[0],[1.0])|(14,[10],[1.0])                              |\n",
      "|false       |false        |false       |false   |true        |false    |true    |false     |false      |false    |(4,[1],[1.0])|(14,[4,6,11],[1.0,1.0,1.0])                  |\n",
      "|false       |false        |false       |false   |false       |false    |true    |false     |false      |false    |(4,[0],[1.0])|(14,[6,10],[1.0,1.0])                        |\n",
      "|true        |false        |false       |true    |false       |false    |true    |true      |false      |false    |(4,[0],[1.0])|(14,[0,3,6,7,10],[1.0,1.0,1.0,1.0,1.0])      |\n",
      "|true        |true         |false       |true    |false       |false    |false   |true      |true       |false    |(4,[0],[1.0])|(14,[0,1,3,7,8,10],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|false       |true         |false       |false   |true        |false    |false   |false     |false      |true     |(4,[0],[1.0])|(14,[1,4,9,10],[1.0,1.0,1.0,1.0])            |\n",
      "|false       |false        |false       |false   |false       |false    |false   |true      |false      |false    |(4,[3],[1.0])|(14,[7,13],[1.0,1.0])                        |\n",
      "|true        |false        |true        |false   |false       |false    |true    |true      |true       |false    |(4,[0],[1.0])|(14,[0,2,6,7,8,10],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|false       |false        |false       |false   |true        |true     |true    |false     |false      |false    |(4,[1],[1.0])|(14,[4,5,6,11],[1.0,1.0,1.0,1.0])            |\n",
      "|false       |false        |true        |false   |true        |true     |false   |false     |false      |false    |(4,[1],[1.0])|(14,[2,4,5,11],[1.0,1.0,1.0,1.0])            |\n",
      "|false       |false        |false       |false   |false       |false    |false   |false     |false      |false    |(4,[3],[1.0])|(14,[13],[1.0])                              |\n",
      "|false       |false        |false       |false   |false       |false    |false   |false     |false      |false    |(4,[0],[1.0])|(14,[10],[1.0])                              |\n",
      "|true        |false        |false       |false   |false       |false    |false   |false     |false      |true     |(4,[0],[1.0])|(14,[0,9,10],[1.0,1.0,1.0])                  |\n",
      "|false       |false        |false       |false   |true        |false    |false   |false     |true       |false    |(4,[1],[1.0])|(14,[4,8,11],[1.0,1.0,1.0])                  |\n",
      "|false       |true         |false       |false   |false       |false    |false   |false     |true       |false    |(4,[1],[1.0])|(14,[1,8,11],[1.0,1.0,1.0])                  |\n",
      "|false       |false        |false       |false   |false       |false    |true    |false     |false      |false    |(4,[0],[1.0])|(14,[6,10],[1.0,1.0])                        |\n",
      "|false       |false        |true        |false   |false       |false    |false   |false     |true       |false    |(4,[0],[1.0])|(14,[2,8,10],[1.0,1.0,1.0])                  |\n",
      "|false       |false        |true        |false   |false       |false    |false   |false     |false      |false    |(4,[3],[1.0])|(14,[2,13],[1.0,1.0])                        |\n",
      "|true        |true         |false       |false   |false       |false    |true    |false     |false      |false    |(4,[0],[1.0])|(14,[0,1,6,10],[1.0,1.0,1.0,1.0])            |\n",
      "|false       |false        |false       |false   |false       |false    |false   |false     |false      |true     |(4,[2],[1.0])|(14,[9,12],[1.0,1.0])                        |\n",
      "+------------+-------------+------------+--------+------------+---------+--------+----------+-----------+---------+-------------+---------------------------------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "%%spark \n",
    "# Only take the relevant columns for this analysis\n",
    "theLikesCols = ['likebroadway', 'likeclassical', 'likeconcerts', 'likejazz', 'likemusicals', 'likeopera', 'likerock', \n",
    "    'likesports', 'liketheatre', 'likevegas']\n",
    "theLikesColsCat = ['likebroadway', 'likeclassical', 'likeconcerts', 'likejazz', 'likemusicals', 'likeopera', 'likerock', \n",
    "    'likesports', 'liketheatre', 'likevegas','catVec']\n",
    "theLikes = encoded.select(theLikesColsCat)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= theLikesColsCat,\n",
    "    outputCol='features')\n",
    "\n",
    "output = assembler.transform(theLikes)\n",
    "output.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate correlations between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dafe1258bb64c1095bb1e5ecfe85378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation matrix:\n",
      "DenseMatrix([[ 1.00000000e+00,  9.28241038e-03,  6.73510930e-03,\n",
      "               8.58018052e-03, -3.06401747e-02, -2.12210957e-03,\n",
      "               1.31785467e-02,  1.59262961e-03, -2.46844969e-03,\n",
      "               2.40210292e-02,  7.24815292e-03, -1.69377222e-02,\n",
      "               1.51163190e-02, -8.42867701e-03],\n",
      "             [ 9.28241038e-03,  1.00000000e+00, -1.27868474e-02,\n",
      "              -4.23328457e-03, -1.21320026e-02, -1.71239117e-02,\n",
      "               1.22971251e-02,  1.76401856e-02,  1.69086121e-02,\n",
      "               1.29868369e-02, -3.64030182e-03,  2.95016027e-03,\n",
      "               7.71830441e-03, -9.29604317e-03],\n",
      "             [ 6.73510930e-03, -1.27868474e-02,  1.00000000e+00,\n",
      "               2.35992773e-02, -4.48751214e-03,  1.74718495e-03,\n",
      "               2.40821540e-03,  7.16380674e-03, -3.89680034e-04,\n",
      "              -2.48151708e-03,  2.13562361e-04, -2.67959647e-03,\n",
      "               1.97862431e-03,  1.22603783e-03],\n",
      "             [ 8.58018052e-03, -4.23328457e-03,  2.35992773e-02,\n",
      "               1.00000000e+00, -1.43327844e-02, -1.61613191e-03,\n",
      "               1.14130571e-02,  2.59175684e-02, -2.14278863e-02,\n",
      "               1.58257789e-02, -7.56235327e-03,  5.12757932e-03,\n",
      "               5.75668853e-03, -1.98802780e-03],\n",
      "             [-3.06401747e-02, -1.21320026e-02, -4.48751214e-03,\n",
      "              -1.43327844e-02,  1.00000000e+00, -1.34513021e-03,\n",
      "              -3.34749126e-03, -2.17101108e-02, -1.81988176e-02,\n",
      "               3.76549627e-03, -6.73206563e-04, -3.09248663e-03,\n",
      "               9.83822207e-04,  5.29099482e-03],\n",
      "             [-2.12210957e-03, -1.71239117e-02,  1.74718495e-03,\n",
      "              -1.61613191e-03, -1.34513021e-03,  1.00000000e+00,\n",
      "               1.03416082e-02,  1.13642152e-02,  1.12299154e-02,\n",
      "              -1.78256663e-02, -1.49693512e-02,  2.32819812e-02,\n",
      "               2.48037207e-03, -1.32982691e-02],\n",
      "             [ 1.31785467e-02,  1.22971251e-02,  2.40821540e-03,\n",
      "               1.14130571e-02, -3.34749126e-03,  1.03416082e-02,\n",
      "               1.00000000e+00,  6.57212056e-03, -9.56907047e-03,\n",
      "              -1.16327949e-02,  1.85460050e-02, -7.50540687e-03,\n",
      "              -1.94929855e-02,  4.19240966e-03],\n",
      "             [ 1.59262961e-03,  1.76401856e-02,  7.16380674e-03,\n",
      "               2.59175684e-02, -2.17101108e-02,  1.13642152e-02,\n",
      "               6.57212056e-03,  1.00000000e+00,  7.04696091e-03,\n",
      "              -1.51304701e-02,  2.53869989e-03, -2.24394969e-04,\n",
      "               7.99737174e-04, -6.08231358e-03],\n",
      "             [-2.46844969e-03,  1.69086121e-02, -3.89680034e-04,\n",
      "              -2.14278863e-02, -1.81988176e-02,  1.12299154e-02,\n",
      "              -9.56907047e-03,  7.04696091e-03,  1.00000000e+00,\n",
      "               1.95736593e-02, -9.88185728e-03, -3.89953948e-03,\n",
      "               2.23461563e-02, -6.60389045e-03],\n",
      "             [ 2.40210292e-02,  1.29868369e-02, -2.48151708e-03,\n",
      "               1.58257789e-02,  3.76549627e-03, -1.78256663e-02,\n",
      "              -1.16327949e-02, -1.51304701e-02,  1.95736593e-02,\n",
      "               1.00000000e+00,  1.86876589e-03, -5.16538750e-03,\n",
      "               9.66854436e-04,  3.66018781e-03],\n",
      "             [ 7.24815292e-03, -3.64030182e-03,  2.13562361e-04,\n",
      "              -7.56235327e-03, -6.73206563e-04, -1.49693512e-02,\n",
      "               1.85460050e-02,  2.53869989e-03, -9.88185728e-03,\n",
      "               1.86876589e-03,  1.00000000e+00, -6.04501590e-01,\n",
      "              -4.83348816e-01, -2.86471024e-01],\n",
      "             [-1.69377222e-02,  2.95016027e-03, -2.67959647e-03,\n",
      "               5.12757932e-03, -3.09248663e-03,  2.32819812e-02,\n",
      "              -7.50540687e-03, -2.24394969e-04, -3.89953948e-03,\n",
      "              -5.16538750e-03, -6.04501590e-01,  1.00000000e+00,\n",
      "              -2.32085186e-01, -1.37552175e-01],\n",
      "             [ 1.51163190e-02,  7.71830441e-03,  1.97862431e-03,\n",
      "               5.75668853e-03,  9.83822207e-04,  2.48037207e-03,\n",
      "              -1.94929855e-02,  7.99737174e-04,  2.23461563e-02,\n",
      "               9.66854436e-04, -4.83348816e-01, -2.32085186e-01,\n",
      "               1.00000000e+00, -1.09984295e-01],\n",
      "             [-8.42867701e-03, -9.29604317e-03,  1.22603783e-03,\n",
      "              -1.98802780e-03,  5.29099482e-03, -1.32982691e-02,\n",
      "               4.19240966e-03, -6.08231358e-03, -6.60389045e-03,\n",
      "               3.66018781e-03, -2.86471024e-01, -1.37552175e-01,\n",
      "              -1.09984295e-01,  1.00000000e+00]])"
     ]
    }
   ],
   "source": [
    "%%spark \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "# Grab just the features; and calc the Pearson correlation matrix\n",
    "features = output.select('features')\n",
    "\n",
    "r1 = Correlation.corr(features, \"features\").head()\n",
    "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e3b9e4af0240d98278a4fc2cf8c9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14)\n",
      "[[ 0.00724815 -0.01693772  0.01511632 -0.00842868]\n",
      " [-0.0036403   0.00295016  0.0077183  -0.00929604]\n",
      " [ 0.00021356 -0.0026796   0.00197862  0.00122604]\n",
      " [-0.00756235  0.00512758  0.00575669 -0.00198803]\n",
      " [-0.00067321 -0.00309249  0.00098382  0.00529099]\n",
      " [-0.01496935  0.02328198  0.00248037 -0.01329827]\n",
      " [ 0.01854601 -0.00750541 -0.01949299  0.00419241]\n",
      " [ 0.0025387  -0.00022439  0.00079974 -0.00608231]\n",
      " [-0.00988186 -0.00389954  0.02234616 -0.00660389]\n",
      " [ 0.00186877 -0.00516539  0.00096685  0.00366019]]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f930dd07e14f38a7219fe24b9b5e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o corrmat\n",
    "# Pull out the subsection of the correlation array of interest: Likes, vs Categories\n",
    "corrArr = r1[0].toArray()\n",
    "print(corrArr.shape)\n",
    "corrs = corrArr[0:len(theLikesCols), len(theLikesCols):]\n",
    "print(corrs)\n",
    "corrs.shape\n",
    "\n",
    "# Convert to dataframe, for use by Local\n",
    "pdf = pd.DataFrame(corrs, columns=theCorrCols)\n",
    "corrmat = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\n",
      "\u001b[K     |████████████████████████████████| 283 kB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.23\n",
      "  Downloading pandas-1.1.4-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from seaborn) (1.19.2)\n",
      "Collecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 41.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.0\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 50.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2020.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 41.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
      "Installing collected packages: pandas, cycler, kiwisolver, pillow, matplotlib, scipy, seaborn\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "hdijupyterutils 0.12.9 requires jupyter>=1, which is not installed.\u001b[0m\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3 pandas-1.1.4 pillow-8.0.1 scipy-1.5.4 seaborn-0.11.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/JupyterSystemEnv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "# Install a pip package - Seaborn - in the current Jupyter kernel, for use in plotting\n",
    "import sys\n",
    "!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the local notebook, retrieve the correlations (which is a small dataset), and plot the correlations as a heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip insta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsns.heatmap(corrmat, annot=True, fmt=\"g\", cmap=\\'viridis\\',\\n            yticklabels=theLikesCols)\\n           # xticklabels=corr.columns)\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Must redefine this variable here, since Local and Spark do not share vars\n",
    "theLikesCols = ['likebroadway', 'likeclassical', 'likeconcerts', 'likejazz', 'likemusicals', 'likeopera', 'likerock', \n",
    "    'likesports', 'liketheatre', 'likevegas']\n",
    "#theCorrCols = ['catVec0', 'catVec1','catVec2']\n",
    "# plot the heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pcolor(corrmat)\n",
    "'''\n",
    "sns.heatmap(corrmat, annot=True, fmt=\"g\", cmap='viridis',\n",
    "            yticklabels=theLikesCols)\n",
    "           # xticklabels=corr.columns)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that, based on these ticket purchases and event attendances, the likes and event categories are only very weakly correlated (max correlation is 0.02). Though the correlations are weak, relatively speaking:\n",
    "- Liking Theatre is positively correlated with Musicals\n",
    "- Liking Opera is positively correlated with Plays\n",
    "- Liking Rock is negatively correlated with Musicals\n",
    "- Liking Broadway is negatively correlated with Plays (surprisingly!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can move on to other analyses, such as looking at user locations vs event locations; holidays and weekends versus weekdays, and other correlations. These kinds of correlations can help understand the user base and help in developing a recommendation engine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, cleanup all sessions from this notebook, if you're done. (Can also be useful in case there are other sessions hanging around using up resources.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cleanup -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "widgets": {
   "state": {
    "034842d547674db694a02e123211a305": {
     "views": []
    },
    "074b23332439401592c6c4054f588dad": {
     "views": []
    },
    "0885b1a904d3424096810bf1116a3e9d": {
     "views": []
    },
    "0bfcee70c34247b3959bb63e7fc77a71": {
     "views": []
    },
    "0e3bfbb104cd4b1fbc02a30de6580df2": {
     "views": []
    },
    "11df1ff0971f4e4386a524901d9b20ba": {
     "views": []
    },
    "1396d1c4cda74680a41c882715387c73": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "141e57b199094edc8105b0610af1428f": {
     "views": []
    },
    "14c9eb6b1db040fc8dcf09f9ec665d19": {
     "views": []
    },
    "184fa1e2bb4b4521859a74402927ae8a": {
     "views": []
    },
    "192cf0c7231949e4b145c3432a2491d3": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "19dbb4c7963a41cd91db658ca2083f51": {
     "views": []
    },
    "19e5be7f7ba547f58bc75e76ed36a2b8": {
     "views": []
    },
    "214fecaca5e0460dafed45cb31da4be7": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "22a5797ffc2d469784014404d82a47f9": {
     "views": []
    },
    "22ca476ddb4645e6b6cb75071e9ee2f9": {
     "views": []
    },
    "23139acf7a6f453396c3a3b68197586b": {
     "views": []
    },
    "24320b3bddbc4ea4a0259ce82c1e4759": {
     "views": []
    },
    "259edcc74da2485c8ce0866e44efa9b0": {
     "views": []
    },
    "26554f042c674c83b6a81701545dac0b": {
     "views": []
    },
    "28226795a7e44d0297339b6f5259f122": {
     "views": []
    },
    "2aa925686dea495eab2d83bf3c43e32d": {
     "views": []
    },
    "2e46ff0e5268466b8843f57a09643232": {
     "views": []
    },
    "2feba535f6f7436dbb26aba1c2f84425": {
     "views": []
    },
    "30ed6638416f4846999f2b6be3ecbb2c": {
     "views": []
    },
    "3166b6555f7d495d9bb251f5ed1c7c9d": {
     "views": []
    },
    "3268208b0a394cd99899a893292164ff": {
     "views": []
    },
    "3504347b556948eb99c30ccb620040ac": {
     "views": []
    },
    "38fb69c2361f4a089fa17ae4e8df3f68": {
     "views": []
    },
    "3914382ac3f64a94819dd565145e668e": {
     "views": []
    },
    "3a1fe50c31464de4bbe0f16e09d917b7": {
     "views": []
    },
    "3a55f05a284046ff99eedf4fadd3652a": {
     "views": []
    },
    "3cd222b658e34662af3896acbf2e7d55": {
     "views": []
    },
    "3d62b5d649cb42eb8f56b1ae5b2d6d5b": {
     "views": []
    },
    "402ea933da724f158e7138c55335da28": {
     "views": []
    },
    "42dd42bef2e34611a06f00bccdfd0ed0": {
     "views": []
    },
    "450b0a056d514f7ca645ad72699dccb2": {
     "views": []
    },
    "468cdf8133814989aea154636da80330": {
     "views": []
    },
    "47fd3f9fc86040db8da50fa5b2b783dc": {
     "views": []
    },
    "484215ba5bce487baa14d4c8035c3651": {
     "views": []
    },
    "49d228af2e2242ef80c1718bcc39c1c5": {
     "views": []
    },
    "4c359ee4c0b541efb9f3c976f459f216": {
     "views": []
    },
    "4f4dfd3a9c8e41569b04d329a76bd510": {
     "views": []
    },
    "52ccff6a06204618bd8596c79138b5f6": {
     "views": []
    },
    "5388ecfe135f4aceb2df557361c31b6f": {
     "views": []
    },
    "5530df53ff8848aa9dfc7c0056a84c33": {
     "views": []
    },
    "56fc65076377407da7595f81e85c526c": {
     "views": []
    },
    "571268157ce744dead6260c9e50fc96a": {
     "views": []
    },
    "5a11c59b42184e5bb099a546c424d7ae": {
     "views": []
    },
    "5b80bd7f072c458b81be90643483b8bc": {
     "views": []
    },
    "5ba42de38188412f812314be02f68ec0": {
     "views": []
    },
    "5f3c200ee6644011b2562b7c912923a2": {
     "views": []
    },
    "609023f4ee2c48b99c2b88d94da8f29a": {
     "views": []
    },
    "60cec193ee9f4635a0cfaf72d5dbe53b": {
     "views": []
    },
    "61c9b91b35214d73988fc9fc001f6176": {
     "views": []
    },
    "62cf073829db4cf2b42c920cca3a5a50": {
     "views": []
    },
    "62f91ed2b81542a69e38c8938fe838b1": {
     "views": []
    },
    "6727f64ab0d74e6497eb574135490147": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "67a6a7eb5d944e0ca5ce5423bd07e914": {
     "views": []
    },
    "6c9e901f48294b1d9b081815ff7cda45": {
     "views": []
    },
    "6dc281639cf4400f8ec7a6e3e9a03c1c": {
     "views": []
    },
    "6edcd93c92c74cd2aece127bba97519a": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "6f8eb4cfc0b84ef0a3b4bd2fff618049": {
     "views": []
    },
    "727031474bfa4433a58e27db7e49c8b1": {
     "views": []
    },
    "7671acb7e00c43348333a4590c145e17": {
     "views": []
    },
    "76b5b5dd82fb4ef5a979068241be9bfc": {
     "views": []
    },
    "78e92a0c28724e738d2cbe3fe996b31f": {
     "views": []
    },
    "796da4892f12465a9a6fe1189ef08efc": {
     "views": []
    },
    "7a8752a4c4884edaaf9693fa61cdb773": {
     "views": []
    },
    "7e7c938d937247aa9f94858dba6f6a78": {
     "views": []
    },
    "83f95564c1194571ade5109f6253c577": {
     "views": []
    },
    "85f655ea9f054df7b13d017996651476": {
     "views": []
    },
    "86a79e9cc4e448fd911a87c584f172a4": {
     "views": []
    },
    "87f721cdf41549188f7aeb6e6122852b": {
     "views": []
    },
    "881e643973b04333a0ceb8893853ef2d": {
     "views": []
    },
    "89c7275548b14eccae10923d4611cfcc": {
     "views": []
    },
    "89efa1f11c5849bcb09e122666fe976d": {
     "views": []
    },
    "8c69e56e066e4945a878efd2a62fdcfe": {
     "views": []
    },
    "93246d82cb0b4c77b85cf55b9dc99608": {
     "views": []
    },
    "963372574c6d44199726238990ccce39": {
     "views": []
    },
    "964bf254f1d74526824ca6f37dff7855": {
     "views": []
    },
    "971bca7ae0d04308875eeb634914c4f2": {
     "views": []
    },
    "9933ae3e398d4671aff037213914efb0": {
     "views": []
    },
    "9990ec24af4e459487873d9d44085f27": {
     "views": []
    },
    "9b73ecc79eb94cd2bd26031596c402c4": {
     "views": []
    },
    "9b988e5ff1dc40a69e5cdb5fdb8a6bfd": {
     "views": []
    },
    "9d664e398b4a4d3ab7e22cb119d4f5b4": {
     "views": []
    },
    "9ef67d0355ca4345adb257bd1235f9e6": {
     "views": []
    },
    "a2a07c5c277f4e38bb0029720fb22bdc": {
     "views": []
    },
    "a3452b2fdfd24400aa3ad22171d4c8ff": {
     "views": []
    },
    "a44af55cd42344948cf57b61f54ed0dd": {
     "views": []
    },
    "a78f84a286b441c3ab4aa68f7f48960b": {
     "views": []
    },
    "aa0848583b2f469ea2d96af460377c1e": {
     "views": []
    },
    "ab814dce4cf347af91f8a74c0a9cdfee": {
     "views": []
    },
    "acf967842b5f4f219d2c58a2bd90e2c5": {
     "views": []
    },
    "b0e0f3e0ce2b4624bc771cca3c525d20": {
     "views": []
    },
    "b34816d2685e4584bba941d762e012e1": {
     "views": []
    },
    "b43f74458700439a986e303f951a53e1": {
     "views": []
    },
    "b49b957cfbee4d308d0029f08e003a12": {
     "views": []
    },
    "b844b723a3b541c9a634c3236ef81c97": {
     "views": []
    },
    "b883c2740ec342c3bd02903e88587eb4": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "b9022cf0242c487393de8378076c6598": {
     "views": []
    },
    "b996694eb6fd4ca28b0f0b21dd495775": {
     "views": []
    },
    "bcc2d991d65e431e8c2323e1f1187373": {
     "views": []
    },
    "beb96ca03c3344c38be632180df76248": {
     "views": []
    },
    "c1127c2009c24ae19eb30d384513a8a8": {
     "views": []
    },
    "c19c4b9d5501489eb23ceb6d02114ef7": {
     "views": []
    },
    "c1b1e1bd49b34efbbcd87687bc2ed373": {
     "views": []
    },
    "c452a6e4a41f44289ec5bcea5d4d0f0e": {
     "views": []
    },
    "c4aaea9cc5ec4cfe8e574e742ad981ee": {
     "views": []
    },
    "c81fb3d731724b1a8397f61987fbba86": {
     "views": []
    },
    "c8631c9cbbc24de4b8b110340b99877b": {
     "views": []
    },
    "cb5e49411cc74b169587080b3d5f2da6": {
     "views": []
    },
    "d0d913a1831b4d8d911daf918719634f": {
     "views": []
    },
    "d54b02c556734ca183a850e3aba38978": {
     "views": []
    },
    "d962348cde034617aadb66959a787c0b": {
     "views": []
    },
    "dfa1aca753944c9493ad62f3210da30e": {
     "views": []
    },
    "e15eaf8613ef4969b100caf585ae903c": {
     "views": []
    },
    "e801a7365ba549179ee6318aed84c62e": {
     "views": []
    },
    "ed58a4dc63fd43aaa3890b97bd56f0e1": {
     "views": []
    },
    "ef2bf76cc81948b8bf473a24c773a7d5": {
     "views": []
    },
    "f3ca79a38b7f47dc99d0bd05045563ca": {
     "views": []
    },
    "f71f17bf315e44ed86e45c969149ce73": {
     "views": []
    },
    "f7a26e628e124fe398cf923aa28cc3f1": {
     "views": []
    },
    "f7f64dc4a61a4feba8a949fdd95cf160": {
     "views": []
    },
    "f87fbf5a6a364f9eabae4e2359ec1211": {
     "views": []
    },
    "fa183906e57f4bb288e28b5943c1ff8b": {
     "views": []
    },
    "fa471c60fed2497c843aac04ddcd91d5": {
     "views": []
    },
    "fdd9aebb66434141b34c5e7774f0ed58": {
     "views": []
    },
    "fe0ca149686a4923bd12abbce63b3ca6": {
     "views": []
    },
    "fe649b813cf149b394a8eedc55c57b40": {
     "views": []
    },
    "ffe58d245f764d7090211256ef851500": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
